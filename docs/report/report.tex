\documentclass[a4paper,11pt]{article}
\usepackage{fullpage}           %   set page margins to 1.5
\usepackage{amsmath}            %   align equations
\usepackage{amssymb}            %   math symbols
\usepackage{booktabs}           %   better tables
\usepackage{float}              %   float options
\usepackage[hidelinks]{hyperref}           %   hyperlinks
\usepackage{graphicx}           %   images
\usepackage[brazilian]{babel}   %   pt-br

% change default font family to sans-serif
\renewcommand{\familydefault}{\sfdefault}

\title{\textbf{Implementação Paralela de Random Forest usando OpenMP}}
\author{Eduardo Birkheuer da Silva \and João Pedro Ferreira Pereira \and Walter Frank}
\date{}

\begin{document}

\maketitle

\vspace{2cm}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.25\textwidth]{inf_logo.png}
\end{figure}
\begin{center}
    INF01017 - Programação Distribuída e Paralela
\end{center}

\vspace{2cm}



\newpage
\tableofcontents
\newpage

\section{Introdução}

Este relatório apresenta a implementação e análise de um algoritmo Random Forest paralelo usando OpenMP. O trabalho visa demonstrar melhorias de desempenho através da paralelização e analisar o comportamento da aplicação usando o Intel VTune Profiler.

\subsection{Visão Geral do Algoritmo Random Forest}
Floresta aleatória ou floresta de decisão é um método de aprendizado de máquina do tipo ensemble que constrói múltiplas árvores de decisão durante o treinamento para realizar a classificação de dados ou regressão. No caso da classificação, a previsão final é dada por votação majoritária simples das árvores. Já na regressão, a previsão final é dada pela média das previsões das árvores.

\subsection{Objetivos}
\begin{itemize}
    \item Implementar versões sequencial e paralela do Random Forest
    \item Analisar melhorias de desempenho com diferentes números de threads
    \item Identificar gargalos e oportunidades de otimização usando VTune
    \item Avaliar escalabilidade e eficiência da implementação paralela
\end{itemize}

\section{Detalhes da Implementação}

\subsection{Implementação Sequencial}

A implementação sequencial do Random Forest segue o algoritmo clássico proposto por Breiman, combinando técnicas de bagging (bootstrap aggregating) com aleatoriedade de características para criar um ensemble de árvores de decisão.

\textbf{Estrutura de Dados Principal:}

O sistema utiliza uma estrutura modular composta por:
\begin{itemize}
    \item \texttt{Dataset}: Estrutura para armazenar características (features) e rótulos (labels) dos dados
    \item \texttt{TreeNode}: Nó de árvore contendo índice da característica, threshold de divisão, filhos e predição (para folhas)
    \item \texttt{DecisionTree}: Árvore de decisão implementada como array de nós para eficiência de memória
    \item \texttt{RandomForest}: Ensemble contendo array de árvores e hiperparâmetros
\end{itemize}

\textbf{Algoritmo de Treinamento:}

O processo de treinamento segue os seguintes passos:

1. \textbf{Amostragem Bootstrap:} Para cada árvore, é criada uma amostra bootstrap do conjunto de treinamento original, mantendo o mesmo tamanho mas permitindo repetições de amostras.

2. \textbf{Seleção Aleatória de Características:} Cada árvore utiliza apenas um subconjunto aleatório de características, calculado como $\sqrt{n_{features}}$ por padrão, selecionadas sem reposição.

3. \textbf{Construção da Árvore de Decisão:} Cada árvore é construída recursivamente usando um algoritmo guloso similar ao CART:
   \begin{itemize}
       \item \textbf{Critério de Divisão:} Impureza de Gini ($Gini = 1 - \sum_{i} p_i^2$)
       \item \textbf{Busca Exaustiva:} Testa todas as características disponíveis e todos os thresholds possíveis
       \item \textbf{Estratégia de Threshold:} Utiliza pontos médios entre valores consecutivos ordenados
       \item \textbf{Divisão Binária:} Cada nó interno divide amostras em dois grupos: $feature \leq threshold$ (esquerda) e $feature > threshold$ (direita)
   \end{itemize}

4. \textbf{Critérios de Parada:} A construção de cada árvore para quando:
   \begin{itemize}
       \item Profundidade máxima atingida (padrão: 10 níveis)
       \item Número mínimo de amostras para divisão não alcançado (padrão: 2 amostras)
       \item Nó completamente puro (impureza de Gini = 0)
       \item Nenhuma divisão melhora a impureza
   \end{itemize}

\textbf{Algoritmo de Predição:}

A predição segue um processo de votação majoritária:
\begin{enumerate}
    \item Cada árvore faz uma predição individual navegando desde a raiz até uma folha
    \item A navegação segue as condições de divisão: se $feature[i] \leq threshold$, vai para filho esquerdo, senão para o direito
    \item Nas folhas, retorna a classe majoritária das amostras de treinamento que chegaram àquele nó
    \item A predição final do ensemble é a classe mais votada entre todas as árvores
\end{enumerate}

\textbf{Componentes Principais:}
\begin{itemize}
    \item Construção de árvore de decisão usando algoritmo guloso similar a CART
    \item Amostragem bootstrap do conjunto de treinamento para cada árvore
    \item Seleção aleatória de subconjunto de características (features) para cada árvore
    \item Divisão recursiva de nodos buscando thresholds e features que minimizam a impureza de Gini
    \item Critérios de parada: profundidade máxima ou número mínimo de amostras por nodo
    \item Agregação de predições através de votação majoritária (classificação) ou média (regressão)
\end{itemize}

\subsection{Estratégia de Implementação Paralela}

\subsubsection{Abordagem de Paralelização}

A paralelização do algoritmo Random Forest foi implementada seguindo uma estratégia de múltiplos níveis, aproveitando as características naturalmente paralelas do algoritmo. A abordagem principal baseia-se no fato de que o treinamento de cada árvore da floresta é completamente independente, permitindo paralelização em nível de árvore. Adicionalmente, foram identificados e paralelizados outros pontos críticos do algoritmo para maximizar o desempenho.

A estratégia de paralelização implementada contempla quatro principais áreas de otimização:

\begin{enumerate}
    \item \textbf{Paralelização do Treinamento de Árvores:} Distribuição das árvores da floresta entre threads diferentes
    \item \textbf{Paralelização da Busca por Melhor Split:} Distribuição dos potenciais pontos de divisão entre threads
    \item \textbf{Paralelização da Predição:} Distribuição das árvores durante o processo de inferência
    \item \textbf{Paralelização da Avaliação de Precisão:} Processamento paralelo das amostras de teste
\end{enumerate}

\textbf{Diretivas OpenMP Utilizadas:}
\begin{itemize}
    \item \texttt{\#pragma omp parallel for schedule(static)} - Distribuição estática de iterações entre threads para treinamento e predição
    \item \texttt{\#pragma omp critical} - Proteção de seções críticas durante atualizações de variáveis compartilhadas
    \item \texttt{\#pragma omp reduction(+:correct\_predictions)} - Redução paralela para soma thread-safe na avaliação de precisão
    \item \texttt{\#pragma omp atomic capture} - Operações atômicas para contadores compartilhados
    \item \texttt{\#pragma omp parallel} com \texttt{\#pragma omp for nowait} - Regiões paralelas com distribuição de trabalho sem sincronização
\end{itemize}

\subsubsection{Decisões de Design e Justificativas}

\textbf{Decisão 1:} Paralelização do Treinamento de Árvores da Floresta
\begin{itemize}
    \item \textbf{Justificativa:} Esta foi a primeira e mais óbvia otimização, visto que o treinamento de cada árvore é totalmente independente das demais. Cada árvore utiliza uma amostra bootstrap diferente e um subconjunto aleatório de características, não havendo dependências entre as árvores.
    \item \textbf{Implementação:} Utilização de \texttt{\#pragma omp parallel for schedule(static)} na função \texttt{train\_random\_forest}, permitindo que cada thread processe um subconjunto das árvores de forma balanceada.
    \item \textbf{Trade-offs:} Proporciona excelente escalabilidade com overhead mínimo, mas requer cuidado com o gerenciamento de memória para evitar condições de corrida durante a alocação de estruturas das árvores.
\end{itemize}

\textbf{Decisão 2:} Paralelização da Busca pelo Melhor Split
\begin{itemize}
    \item \textbf{Justificativa:} A busca pelo melhor ponto de divisão representa uma porção significativa do tempo computacional, especialmente com muitas características. Cada potencial split pode ser avaliado independentemente.
    \item \textbf{Implementação:} Implementação de região paralela com \texttt{\#pragma omp parallel} seguido de \texttt{\#pragma omp for nowait schedule(static)} na função \texttt{find\_best\_split}, onde cada thread mantém variáveis locais para o melhor resultado e utiliza seção crítica para atualizar o resultado global.
    \item \textbf{Trade-offs:} Melhora significativa de desempenho em datasets com muitas características, mas pode introduzir overhead em datasets pequenos devido ao custo de sincronização.
\end{itemize}

\textbf{Decisão 3:} Paralelização da Predição das Árvores
\begin{itemize}
    \item \textbf{Justificativa:} Durante a fase de predição, cada árvore pode fazer sua predição independentemente, e a votação majoritária pode ser calculada de forma paralela.
    \item \textbf{Implementação:} Distribuição das árvores entre threads usando \texttt{\#pragma omp parallel for schedule(static)} na função \texttt{predict\_random\_forest}, permitindo que cada thread processe um subconjunto das árvores da floresta.
    \item \textbf{Trade-offs:} Acelera significativamente a fase de inferência, especialmente importante para florestas grandes, com overhead mínimo para sincronização de resultados.
\end{itemize}

\textbf{Decisão 4:} Paralelização da Avaliação de Precisão
\begin{itemize}
    \item \textbf{Justificativa:} A avaliação da precisão envolve processar múltiplas amostras de teste independentemente, sendo naturalmente paralelizável.
    \item \textbf{Implementação:} Utilização de \texttt{\#pragma omp parallel for reduction(+:correct\_predictions)} na função \texttt{evaluate\_accuracy}, permitindo que cada thread processe um subconjunto das amostras e contribua para o contador total de predições corretas de forma thread-safe.
    \item \textbf{Trade-offs:} Oferece speedup proporcional ao número de amostras de teste, com a vantagem de usar redução automática do OpenMP para evitar condições de corrida.
\end{itemize}

\section{Configuração Experimental}

\subsection{Ambiente de Hardware e Software}
\begin{itemize}
    \item \textbf{Processador:} 2 x Intel(R) Xeon(R) E5-2650 v3, 2.30 GHz, 40 threads, 20 cores
    \item \textbf{Memória:} 128 GB DDR4
    \item \textbf{Sistema Operacional:} Debian 12.1
    \item \textbf{Compilador:} Gcc 12.2.0 -Wall -Wextra -O3 -fopenmp -std=c++17
    \item \textbf{Versão OpenMP:} 5.1
\end{itemize}

\subsection{Conjuntos de Dados}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Dataset} & \textbf{Tamanho} & \textbf{Características} & \textbf{Amostras} \\
\hline
Iris Test & 627B & 5 & 30 \\
\hline
Student Performance Small & 813KB & 6 & 30000 \\
\hline
Credit Card Small & 4.0MB & 31 & 8000\\
\hline
Company Bankruptcy & 11MB & 96 & 6819 \\
\hline
\end{tabular}
\end{table}

\subsection{Metodologia de Teste}
\begin{itemize}
    \item \textbf{Números de threads testados:} 1, 2, 4, 8, 12, 16, 20, 24
    \item \textbf{Iterações por teste:} 5 (para significância estatística)
    \item \textbf{Métricas coletadas:} Tempo de execução, precisão
\end{itemize}

\section{Resultados de Desempenho}

\subsection{Análise do Tempo de Execução}







\textbf{Observações Principais:}
\begin{itemize}
    \item Em datasets pequenos, o overhead de gerenciamento de threads se torna significativo muito rapidamente, já causando uma degradação de desempenho ap usar mais do que 8 threads
    \item O desempenho dos datasets deixa de aumentar depois que o número de threads ultrapassa o número de cores físicos do processador
    \item O desempenho ótimo é alcançado com 20 threads
\end{itemize}

\subsection{Análise de Speedup}

\textbf{Fórmula de Speedup:} $S(p) = T(1) / T(p)$

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../../pcad_results/graphs/all_datasets_speedup.png}
    \caption{Tempo de Execução para todos os datasets}
\end{figure}

\textbf{Resumo dos Resultados:}
\begin{itemize}
    \item \textbf{Melhor speedup alcançado:} [valor] com [número de threads] threads
    \item \textbf{Faixa de speedup linear:} [faixa de threads]
    \item \textbf{Degradação de speedup:} [além de qual número de threads]
\end{itemize}

\subsection{Análise de Eficiência}

\textbf{Fórmula de Eficiência:} $E(p) = S(p) / p$

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../../pcad_results/graphs/all_datasets_execution_time.png}
    \caption{Tempo de Execução para todos os datasets}
\end{figure}

\textbf{Análise de Eficiência:}
\begin{itemize}
    \item \textbf{Eficiência máxima:} [valor] com [número de threads] threads
    \item \textbf{Limiar de eficiência:} [valor] onde eficiência cai abaixo de 70\%
    \item \textbf{Limite de escalabilidade:} [análise de quando eficiência degrada significativamente]
\end{itemize}

\section{Análise do Intel VTune Profiler}

\subsection{Análise de Snapshot de Desempenho}

[Inserir resultados de snapshot de desempenho do VTune]

\textbf{Métricas Principais:}
\begin{itemize}
    \item \textbf{Utilização de CPU:} [porcentagem]
    \item \textbf{Uso de Memória:} [análise]
    \item \textbf{Eficiência de Threading:} [análise]
\end{itemize}

\subsection{Análise de Hotspots}

[Inserir resultados de análise de hotspots]

\textbf{Principais Consumidores de CPU:}
\begin{enumerate}
    \item [Nome da função] - [porcentagem] do tempo de execução
    \item [Nome da função] - [porcentagem] do tempo de execução
    \item [Nome da função] - [porcentagem] do tempo de execução
\end{enumerate}

\textbf{Oportunidades de Otimização:}
\begin{itemize}
    \item [Oportunidade 1 com explicação]
    \item [Oportunidade 2 com explicação]
\end{itemize}

\subsection{Análise de Desempenho HPC}

[Inserir resultados de desempenho HPC]

\textbf{Métricas Paralelas:}
\begin{itemize}
    \item \textbf{Tempo Paralelo:} [porcentagem]
    \item \textbf{Tempo Serial:} [porcentagem]
    \item \textbf{Balanceamento de Carga:} [análise]
    \item \textbf{Contenção de Locks:} [se houver]
\end{itemize}

\section{Discussão}

\subsection{Análise de Desempenho}
[Discussão detalhada dos resultados]

\subsection{Gargalos Identificados}
[Análise das limitações de desempenho]

\subsection{Comparação com Expectativas Teóricas}
[Como os resultados se comparam às previsões da lei de Amdahl]

\subsection{Limitações e Trabalhos Futuros}
[Discutir limitações atuais e potenciais melhorias]

\section{Conclusões}

[Resumo das principais descobertas e conquistas]

\textbf{Principais Contribuições:}
\begin{itemize}
    \item [Contribuição 1]
    \item [Contribuição 2]
    \item [Contribuição 3]
\end{itemize}

\textbf{Resumo de Desempenho:}
\begin{itemize}
    \item \textbf{Speedup máximo alcançado:} [valor]
    \item \textbf{Configuração ótima de threads:} [detalhes]
    \item \textbf{Eficiência na configuração ótima:} [valor]
\end{itemize}

\section{Referências}

[Referências acadêmicas e fontes de documentação]

\section{Apêndices}

\subsection{Estrutura do Código Fonte}
[Breve visão geral da organização do código]

\subsection{Instruções de Compilação}
[Instruções detalhadas de build]

\subsection{Dados Completos de Desempenho}
[Tabelas detalhadas de desempenho]

\end{document}